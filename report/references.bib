@misc{github_repository,
  author = {Abdus Salam Khazi},
  howpublished = "\href{https://github.com/abduskhazi/ranking-loss-surrogates.git}{Code}",
  note = "[Online; accessed 9-May-2022]"
}

@misc{DeepEnsemblePaper,
  doi = {10.48550/ARXIV.1612.01474},
  
  url = {https://arxiv.org/abs/1612.01474},
  
  author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{fsbopaper,
  doi = {10.48550/ARXIV.2101.07667},
  
  url = {https://arxiv.org/abs/2101.07667},
  
  author = {Wistuba, Martin and Grabocka, Josif},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Few-Shot Bayesian Optimization with Deep Kernel Surrogates},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{patacchiola2020bayesian,
  title={Bayesian Meta-Learning for the Few-Shot Setting via Deep Kernels},
  author={Patacchiola, Massimiliano and Turner, Jack and Crowley, Elliot J. and Storkey, Amos},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}


@InProceedings{pmlr-v51-wilson16,
  title = 	 {Deep Kernel Learning},
  author = 	 {Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P.},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {370--378},
  year = 	 {2016},
  editor = 	 {Gretton, Arthur and Robert, Christian C.},
  volume = 	 {51},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Cadiz, Spain},
  month = 	 {09--11 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v51/wilson16.pdf},
  url = 	 {https://proceedings.mlr.press/v51/wilson16.html},
  abstract = 	 {We introduce scalable deep kernels, which combine the structural properties of deep learning architectures with the non-parametric flexibility of kernel methods.  Specifically, we transform the inputs of a spectral mixture base kernel with a deep architecture, using local kernel interpolation, inducing points, and structure exploiting (Kronecker and Toeplitz) algebra for a scalable kernel representation.  These closed-form kernels can be used as drop-in replacements for standard kernels, with benefits in expressive power and scalability.  We jointly learn the properties of these kernels through the marginal likelihood of a Gaussian process.  Inference and learning cost O(n) for n training points, and predictions cost O(1) per test point.  On a large and diverse collection of applications, including a dataset with 2 million examples, we show improved performance over scalable Gaussian processes with flexible kernel learning models, and stand-alone deep architectures.}
}


@inproceedings{SMBOPaper,
author = {Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
title = {Sequential Model-Based Optimization for General Algorithm Configuration},
year = {2011},
isbn = {9783642255656},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-25566-3_40},
doi = {10.1007/978-3-642-25566-3_40},
abstract = {State-of-the-art algorithms for hard computational problems often expose many parameters that can be modified to improve empirical performance. However, manually exploring the resulting combinatorial space of parameter settings is tedious and tends to lead to unsatisfactory outcomes. Recently, automated approaches for solving this algorithm configuration problem have led to substantial improvements in the state of the art for solving various problems. One promising approach constructs explicit regression models to describe the dependence of target algorithm performance on parameter settings; however, this approach has so far been limited to the optimization of few numerical algorithm parameters on single instances. In this paper, we extend this paradigm for the first time to general algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances. We experimentally validate our new algorithm configuration procedure by optimizing a local search and a tree search solver for the propositional satisfiability problem (SAT), as well as the commercial mixed integer programming (MIP) solver CPLEX. In these experiments, our procedure yielded state-of-the-art performance, and in many cases outperformed the previous best configuration approach.},
booktitle = {Proceedings of the 5th International Conference on Learning and Intelligent Optimization},
pages = {507â€“523},
numpages = {17},
location = {Rome, Italy},
series = {LION'05}
}

@misc{GPTutorial,
  doi = {10.48550/ARXIV.2009.10862},
  url = {https://arxiv.org/abs/2009.10862},
  author = {Wang, Jie},
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {An Intuitive Tutorial to Gaussian Processes Regression},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@book{MITMLBook,
author = {Murphy, Kevin P.},
title = {Machine Learning: A Probabilistic Perspective},
year = {2012},
isbn = {0262018020},
publisher = {The MIT Press},
abstract = {Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students. }
}


@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{deeplearningarticle,
author = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
year = {2015},
month = {05},
pages = {436-44},
title = {Deep Learning},
volume = {521},
journal = {Nature},
doi = {10.1038/nature14539}
}

@incollection{Goan-2020,
	doi = {10.1007/978-3-030-42553-1_3},
  
	url = {https://doi.org/10.1007%2F978-3-030-42553-1_3},
  
	year = 2020,
	publisher = {Springer International Publishing},
  
	pages = {45--87},
  
	author = {Ethan Goan and Clinton Fookes},
  
	title = {Bayesian Neural Networks: An Introduction and Survey},
  
	booktitle = {Case Studies in Applied Bayesian Data Science}
}

@article{JMLR:v15:srivastava14a,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929-1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@article{DBLP:journals/corr/abs-2106-06257,
  author    = {Sebastian Pineda{-}Arango and
               Hadi S. Jomaa and
               Martin Wistuba and
               Josif Grabocka},
  title     = {{HPO-B:} {A} Large-Scale Reproducible Benchmark for Black-Box {HPO}
               based on OpenML},
  journal   = {CoRR},
  volume    = {abs/2106.06257},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.06257},
  eprinttype = {arXiv},
  eprint    = {2106.06257},
  timestamp = {Tue, 15 Jun 2021 16:35:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-06257.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{Jones1998,
author={Jones, Donald R.
and Schonlau, Matthias
and Welch, William J.},
title={Efficient Global Optimization of Expensive Black-Box Functions},
journal={Journal of Global Optimization},
year={1998},
month={Dec},
day={01},
volume={13},
number={4},
pages={455-492},
abstract={In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome.},
issn={1573-2916},
doi={10.1023/A:1008306431147},
url={https://doi.org/10.1023/A:1008306431147}
}

@article{svmhpmetalearnt,
author = {Gomes, Taciana A. F. and Prud\^{e}ncio, Ricardo B. C. and Soares, Carlos and Rossi, Andr\'{e} L. D. and Carvalho, Andr\'{e}},
title = {Combining Meta-Learning and Search Techniques to Select Parameters for Support Vector Machines},
year = {2012},
issue_date = {January, 2012},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {75},
number = {1},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2011.07.005},
doi = {10.1016/j.neucom.2011.07.005},
abstract = {Support Vector Machines (SVMs) have achieved very good performance on different learning problems. However, the success of SVMs depends on the adequate choice of the values of a number of parameters (e.g., the kernel and regularization parameters). In the current work, we propose the combination of meta-learning and search algorithms to deal with the problem of SVM parameter selection. In this combination, given a new problem to be solved, meta-learning is employed to recommend SVM parameter values based on parameter configurations that have been successfully adopted in previous similar problems. The parameter values returned by meta-learning are then used as initial search points by a search technique, which will further explore the parameter space. In this proposal, we envisioned that the initial solutions provided by meta-learning are located in good regions of the search space (i.e. they are closer to optimum solutions). Hence, the search algorithm would need to evaluate a lower number of candidate solutions when looking for an adequate solution. In this work, we investigate the combination of meta-learning with two search algorithms: Particle Swarm Optimization and Tabu Search. The implemented hybrid algorithms were used to select the values of two SVM parameters in the regression domain. These combinations were compared with the use of the search algorithms without meta-learning. The experimental results on a set of 40 regression problems showed that, on average, the proposed hybrid methods obtained lower error rates when compared to their components applied in isolation.},
journal = {Neurocomput.},
month = {jan},
pages = {3â€“13},
numpages = {11},
keywords = {Search, Support vector machines, Meta-learning}
}

@article{metalearningwarmstartpaper,
author = {Reif, Matthias and Shafait, Faisal and Dengel, Andreas},
year = {2012},
month = {06},
pages = {357-380},
title = {Meta-Learning for Evolutionary Parameter Optimization of Classifiers},
volume = {87},
journal = {Machine Learning},
doi = {10.1007/s10994-012-5286-7}
}

@inproceedings{Feurer2018ScalableMF,
  title={Scalable Meta-Learning for Bayesian Optimization using Ranking-Weighted Gaussian Process Ensembles},
  author={Matthias Feurer},
  year={2018}
}

@inproceedings{Feurer2014UsingMT,
  title={Using Meta-Learning to Initialize Bayesian Optimization of Hyperparameters},
  author={Matthias Feurer and Jost Tobias Springenberg and Frank Hutter},
  booktitle={MetaSel@ECAI},
  year={2014}
}

@inproceedings{Schilling2016ScalableHO,
  title={Scalable Hyperparameter Optimization with Products of Gaussian Process Experts},
  author={Nicolas Schilling and Martin Wistuba and Lars Schmidt-Thieme},
  booktitle={ECML/PKDD},
  year={2016}
}

@inproceedings{Wistuba2016TwoStageTS,
  title={Two-Stage Transfer Surrogate Model for Automatic Hyperparameter Optimization},
  author={Martin Wistuba and Nicolas Schilling and Lars Schmidt-Thieme},
  booktitle={ECML/PKDD},
  year={2016}
}

@Article{Weiss2016,
author={Weiss, Karl
and Khoshgoftaar, Taghi M.
and Wang, DingDing},
title={A survey of transfer learning},
journal={Journal of Big Data},
year={2016},
month={May},
day={28},
volume={3},
number={1},
pages={9},
abstract={Machine learning and data mining techniques have been used in numerous real-world applications. An assumption of traditional machine learning methodologies is the training data and testing data are taken from the same domain, such that the input feature space and data distribution characteristics are the same. However, in some real-world machine learning scenarios, this assumption does not hold. There are cases where training data is expensive or difficult to collect. Therefore, there is a need to create high-performance learners trained with more easily obtained data from different domains. This methodology is referred to as transfer learning. This survey paper formally defines transfer learning, presents information on current solutions, and reviews applications applied to transfer learning. Lastly, there is information listed on software downloads for various transfer learning solutions and a discussion of possible future research work. The transfer learning solutions surveyed are independent of data size and can be applied to big data environments.},
issn={2196-1115},
doi={10.1186/s40537-016-0043-6},
url={https://doi.org/10.1186/s40537-016-0043-6}
}


@article{pineda2021hpob,
  author    = {Sebastian Pineda{-}Arango and
               Hadi S. Jomaa and
               Martin Wistuba and
               Josif Grabocka},
  title     = {{HPO-B:} {A} Large-Scale Reproducible Benchmark for Black-Box {HPO}
               based on OpenML},
  journal   = {Neural Information Processing Systems (NeurIPS) Track on Datasets and Benchmarks},
  year      = {2021}
}


@misc{Pobrotyn2020ContextAwareLT,
  doi = {10.48550/ARXIV.2005.10084},
  
  url = {https://arxiv.org/abs/2005.10084},
  
  author = {Pobrotyn, PrzemysÅ‚aw and Bartczak, Tomasz and Synowiec, MikoÅ‚aj and BiaÅ‚obrzeski, RadosÅ‚aw and Bojar, JarosÅ‚aw},
  
  keywords = {Information Retrieval (cs.IR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Context-Aware Learning to Rank with Self-Attention},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{listmlepaper,
  title={Listwise approach to learning to rank: theory and algorithm},
  author={Fen Xia and Tie-Yan Liu and Jue Wang and Wensheng Zhang and Hang Li},
  booktitle={ICML '08},
  year={2008}
}

@misc{tanhstackoverflowanswer,
  title={Are the Q-values of DQN bounded at a single timestep?},
  author={Khazi, Abdus Salam and ddaedalus},
  howpublished = "\url{https://ai.stackexchange.com/questions/31595/are-the-q-values-of-dqn-bounded-at-a-single-timestep/31648#31648}",
  year={2021}
}

@misc{TRLWO,
  doi = {10.48550/ARXIV.1707.05438},
  
  url = {https://arxiv.org/abs/1707.05438},
  
  author = {Chen, Huadong and Huang, Shujian and Chiang, David and Dai, Xinyu and Chen, Jiajun},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Top-Rank Enhanced Listwise Optimization for Statistical Machine Translation},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@article{rshpoarticle,
author = {Bergstra, James and Bengio, Yoshua},
title = {Random Search for Hyper-Parameter Optimization},
year = {2012},
issue_date = {3/1/2012},
publisher = {JMLR.org},
volume = {13},
issn = {1532-4435},
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent "High Throughput" methods achieve surprising success--they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
journal = {J. Mach. Learn. Res.},
month = {feb},
pages = {281â€“305},
numpages = {25},
keywords = {global optimization, deep learning, response surface modeling, neural networks, model selection}
}


@inproceedings{NIPS2011_86e8f7ab,
 author = {Bergstra, James and Bardenet, R\'{e}mi and Bengio, Yoshua and K\'{e}gl, Bal\'{a}zs},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Algorithms for Hyper-Parameter Optimization},
 url = {https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf},
 volume = {24},
 year = {2011}
}

@inproceedings{listwisebetter,
author = {Cao, Zhe and Qin, Tao and Liu, Tie-Yan and Tsai, Ming-Feng and Li, Hang},
title = {Learning to Rank: From Pairwise Approach to Listwise Approach},
year = {2007},
isbn = {9781595937933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1273496.1273513},
doi = {10.1145/1273496.1273513},
abstract = {The paper is concerned with learning to rank, which is to construct a model or a function for ranking objects. Learning to rank is useful for document retrieval, collaborative filtering, and many other applications. Several methods for learning to rank have been proposed, which take object pairs as 'instances' in learning. We refer to them as the pairwise approach in this paper. Although the pairwise approach offers advantages, it ignores the fact that ranking is a prediction task on list of objects. The paper postulates that learning to rank should adopt the listwise approach in which lists of objects are used as 'instances' in learning. The paper proposes a new probabilistic method for the approach. Specifically it introduces two probability models, respectively referred to as permutation probability and top k probability, to define a listwise loss function for learning. Neural Network and Gradient Descent are then employed as model and algorithm in the learning method. Experimental results on information retrieval show that the proposed listwise approach performs better than the pairwise approach.},
booktitle = {Proceedings of the 24th International Conference on Machine Learning},
pages = {129â€“136},
numpages = {8},
location = {Corvalis, Oregon, USA},
series = {ICML '07}
}


@inproceedings{McRank,
 author = {Li, Ping and Wu, Qiang and Burges, Christopher},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Platt and D. Koller and Y. Singer and S. Roweis},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {McRank: Learning to Rank Using Multiple Classification and Gradient Boosting},
 url = {https://proceedings.neurips.cc/paper/2007/file/b86e8d03fe992d1b0e19656875ee557c-Paper.pdf},
 volume = {20},
 year = {2007}
}

@article{procedureforrankinginintro,
author = {Qin, Tao and Liu, Tie-Yan and Xu, Jun and Li, Hang},
year = {2010},
month = {08},
pages = {346-374},
title = {LETOR: A benchmark collection for research on learning to rank for information retrieval},
volume = {13},
journal = {Inf. Retr.},
doi = {10.1007/s10791-009-9123-y}
}

@ARTICLE{pairwisepreferencespaper,  author={Cossock, David and Zhang, Tong},  journal={IEEE Transactions on Information Theory},   title={Statistical Analysis of Bayes Optimal Subset Ranking},   year={2008},  volume={54},  number={11},  pages={5140-5154},  abstract={ The ranking problem has become increasingly important in modern applications of statistical methods in automated decision making systems. In particular, we consider a formulation of the statistical ranking problem which we call subset ranking, and focus on the discounted cumulated gain (DCG) criterion that measures the quality of items near the top of the rank-list. Similar to error minimization for binary classification, direct optimization of natural ranking criteria such as DCG leads to a nonconvex optimization problems that can be NP-hard. Therefore, a computationally more tractable approach is needed. We present bounds that relate the approximate optimization of DCG to the approximate minimization of certain regression errors. These bounds justify the use of convex learning formulations for solving the subset ranking problem. The resulting estimation methods are not conventional, in that we focus on the estimation quality in the top-portion of the rank-list. We further investigate the asymptotic statistical behavior of these formulations. Under appropriate conditions, the consistency of the estimation schemes with respect to the DCG metric can be derived. },  keywords={},  doi={10.1109/TIT.2008.929939},  ISSN={1557-9654},  month={Nov},}

@inproceedings{RankingLossFirstPaperRead,
 author = {Chen, Wei and Liu, Tie-yan and Lan, Yanyan and Ma, Zhi-ming and Li, Hang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. Williams and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Ranking Measures and Loss Functions in Learning to Rank},
 url = {https://proceedings.neurips.cc/paper/2009/file/2f55707d4193dc27118a0f19a1985716-Paper.pdf},
 volume = {22},
 year = {2009}
}

@article{bayesianOptimizationTutorial,
author = {Ahmed, M. O. and Prince, Simon},
year = {2020},
month = {06},
title = {Tutorial 8 - Bayesian optimization},
journal = {BorealisAI},
url = {https://www.borealisai.com/en/blog/tutorial-8-bayesian-optimization/}
}

@book{hutter2019automated,
title = {Automated Machine Learning - Methods, Systems, Challenges},
editor = {Frank Hutter and Lars Kotthoff and Joaquin Vanschoren},
year = {2019},
publisher = {Springer},
keywords = {}
} 

@misc{successivehalving,
  doi = {10.48550/ARXIV.1502.07943},
  
  url = {https://arxiv.org/abs/1502.07943},
  
  author = {Jamieson, Kevin and Talwalkar, Ameet},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Non-stochastic Best Arm Identification and Hyperparameter Optimization},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{HPOAsBilevelOptimization,
  doi = {10.48550/ARXIV.1806.04941},
  
  url = {https://arxiv.org/abs/1806.04941},
  
  author = {Franceschi, Luca and Grazzi, Riccardo and Pontil, Massimiliano and Salzo, Saverio and Frasconi, Paolo},
  
  keywords = {Mathematical Software (cs.MS), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Far-HO: A Bilevel Programming Package for Hyperparameter Optimization and Meta-Learning},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{hypergradient,
  doi = {10.48550/ARXIV.1502.03492},
  
  url = {https://arxiv.org/abs/1502.03492},
  
  author = {Maclaurin, Dougal and Duvenaud, David and Adams, Ryan P.},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Gradient-based Hyperparameter Optimization through Reversible Learning},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@book{hutterneuripstutorial,
title = {AutoML tutorial at NeurIPS 2018},
editor = {Frank Hutter and Joaquin Vanschoren},
year = {2018},
publisher = {online},
url = {https://www.automl.org/wp-content/uploads/2018/12/AutoML-Tutorial-NeurIPS2018-HPO_and_NAS.pdf},
keywords = {}
} 

@article{onlineLearningRateUpdate,
  doi = {10.48550/ARXIV.1703.04782},
  
  url = {https://arxiv.org/abs/1703.04782},
  
  author = {Baydin, Atilim Gunes and Cornish, Robert and Rubio, David Martinez and Schmidt, Mark and Wood, Frank},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, G.1.6; I.2.6, 68T05},
  
  title = {Online Learning Rate Adaptation with Hypergradient Descent},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{gradientbasedHPOtuning,
author = {Luketina, Jelena and Berglund, Mathias and Raiko, Tapani},
year = {2015},
month = {11},
pages = {},
title = {Scalable Gradient-Based Tuning of Continuous Regularization Hyperparameters}
}


@ARTICLE{scoringrules,
title = {Strictly Proper Scoring Rules, Prediction, and Estimation},
author = {Gneiting, Tilmann and Raftery, Adrian E.},
year = {2007},
journal = {Journal of the American Statistical Association},
volume = {102},
pages = {359-378},
url = {https://EconPapers.repec.org/RePEc:bes:jnlasa:v:102:y:2007:p:359-378}
}

@misc{besselcorrection,
    author = "{Wikipedia contributors}",
    title = "Bessel's correction --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2022",
    howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Bessel%27s_correction&oldid=1073637562}",
    note = "[Online; accessed 8-May-2022]"
  }
  
  @inproceedings{positionawarerankinglistmle,
author = {Lan, Yanyan and Zhu, Yadong and Guo, Jiafeng and Niu, Shuzi and Cheng, Xueqi},
year = {2014},
month = {09},
pages = {},
title = {Position-Aware ListMLE: A Sequential Learning Process for Ranking},
journal = {Uncertainty in Artificial Intelligence - Proceedings of the 30th Conference, UAI 2014}
}

